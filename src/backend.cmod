/* -*- c -*-
|| This file is part of Pike. For copyright information see COPYRIGHT.
|| Pike is distributed under GPL, LGPL and MPL. See the file COPYING
|| for more information.
|| $Id: backend.cmod,v 1.70 2003/10/29 19:01:53 mast Exp $
*/

#include "global.h"
RCSID("$Id: backend.cmod,v 1.70 2003/10/29 19:01:53 mast Exp $");
#include "fdlib.h"
#include "backend.h"
#include <errno.h>
#ifdef HAVE_SYS_TYPES_H
#include <sys/types.h>
#endif
#ifdef HAVE_SYS_PARAM_H
#include <sys/param.h>
#endif
#include <string.h>
#include "interpret.h"
#include "object.h"
#include "pike_error.h"
#include "fd_control.h"
#include "main.h"
#include "callback.h"
#include "threads.h"
#include "fdlib.h"
#include <math.h>
#include "interpret.h"
#include "stuff.h"
#include "bignum.h"
#include "svalue.h"
#include "gc.h"

/*
 * Things to do
 *
 * o GC handling for call_out
 *
 *   Well, a call out can never be considered dead since it can always
 *   get called. /mast
 *
 * o what happens to callbacks on destruct?
 *
 * o automatic callback assignment based on current thread
 *
 *   Sounds very odd to me. /mast
 */

#ifdef HAVE_SYS_SELECT_H
#include <sys/select.h>
#else
/* BeOS socket (select etc) stuff */
#ifdef HAVE_NET_SOCKET_H
#include <net/socket.h>
#endif
#endif
#include <sys/stat.h>

#define SELECT_READ 1
#define SELECT_WRITE 2

/* #define POLL_DEBUG */

#ifdef POLL_DEBUG
#define IF_PD(x)	x
#else /* !POLL_DEBUG */
#define IF_PD(x)
#endif /* POLL_DEBUG */

struct cb_data
{
  file_callback callback;
  void * data;
};

struct fd_datum
{
  struct cb_data read, write;
  struct cb_data read_oob, write_oob;
};


#ifndef HAVE_AND_USE_POLL
#undef HAVE_POLL
#endif

#ifdef HAVE_POLL

#ifdef HAVE_POLL_H
#include <poll.h>
#endif /* HAVE_POLL_H */

#ifdef HAVE_SYS_POLL_H
#include <sys/poll.h>
#endif /* HAVE_SYS_POLL_H */

/* Some constants... */

/* Notes on POLLRDNORM and POLLIN:
 *
 * According to the AIX manual, POLLIN and POLLRDNORM are both set
 * if there's a nonpriority message on the read queue. POLLIN is
 * also set if the message is of 0 length.
 */

#ifndef POLLRDNORM
#define POLLRDNORM	POLLIN
#endif /* !POLLRDNORM */

#ifndef POLLRDBAND
#define POLLRDBAND	POLLPRI
#endif /* !POLLRDBAND */

#ifndef POLLWRBAND
#define POLLWRBAND	POLLOUT
#endif /* !POLLWRBAND */

#endif


/* CALL OUT STUFF */

struct call_out_s
{
  INT32 pos;
  struct timeval tv;
  struct call_out_s *next; /* For block alloc */
  struct call_out_s *next_fun;
  struct call_out_s **prev_fun;
  struct call_out_s *next_arr;
  struct call_out_s **prev_arr;
  struct object *caller;
  struct array *args;
};

#include "block_alloc.h"

#ifdef PIKE_DEBUG
#define MESS_UP_BLOCK(X) do {\
 (X)->next_arr=(struct call_out_s *)(ptrdiff_t)-1; \
 (X)->next_fun=(struct call_out_s *)(ptrdiff_t)-1; \
 (X)->prev_arr=(struct call_out_s **)(ptrdiff_t)-1; \
 (X)->prev_fun=(struct call_out_s **)(ptrdiff_t)-1; \
 (X)->caller=(struct object *)(ptrdiff_t)-1; \
 (X)->args=(struct array *)(ptrdiff_t)-1; \
 (X)->pos=-1; \
 } while(0)
#else
#define MESS_UP_BLOCK(X)
#endif

#undef EXIT_BLOCK
#define EXIT_BLOCK(X) do { \
  *(X->prev_arr)=X->next_arr; \
  if(X->next_arr) X->next_arr->prev_arr=X->prev_arr; \
  *(X->prev_fun)=X->next_fun; \
  if(X->next_fun) X->next_fun->prev_fun=X->prev_fun; \
  MESS_UP_BLOCK(X); \
  } while(0)
BLOCK_ALLOC_FILL_PAGES(call_out_s, 2)

typedef struct call_out_s call_out;

struct hash_ent
{
  call_out *arr;
  call_out *fun;
};



DECLARATIONS


struct callback_list do_debug_callbacks;
struct timeval current_time;
struct timeval next_timeout;

/*
 * Stuff to map fds to the proper Backend
 */
static struct Backend_struct **fd_map=0;
static int fd_map_size=0;
struct Backend_struct *default_backend = NULL;

static int backend_do_call_outs(struct Backend_struct *me);
static void backend_verify_call_outs(struct Backend_struct *me);

struct Backend_struct *get_backend_for_fd(int fd)
{
  if(fd<0 || fd>=fd_map_size) return 0;
  return fd_map[fd];
}

static void low_set_backend_for_fd(int fd, struct Backend_struct *b)
{
#ifdef PIKE_DEBUG
  if(fd<0) Pike_fatal("set_backend_for(%d)\n",fd);
#endif
  if (!b) {
    /* Unregister the fd. */
    if (fd < fd_map_size) {
      fd_map[fd] = NULL;
    }
    return;
  }
  if(fd >= fd_map_size)
  {
    int old=fd_map_size;
    if(!fd_map_size) fd_map_size=64;
    while(fd >= fd_map_size) fd_map_size*=2;
    if (fd_map) {
      fd_map = (struct Backend_struct **)
	realloc(fd_map, sizeof(struct Backend_struct *) * fd_map_size);
    } else {
      fd_map = (struct Backend_struct **)
	malloc(sizeof(struct Backend_struct *) * fd_map_size);
    }
    if(!fd_map)
      Pike_fatal("Out of memory in backend:low_set_backend_for_fd.\n"
	"Tried to allocate %d bytes.\n",sizeof(struct Backend_struct *) * fd_map_size);
    
    MEMSET(fd_map+old,0,sizeof(struct Backend_struct *) * (fd_map_size-old));
  }
  fd_map[fd]=b;
}

struct Backend_struct *really_get_backend_for_fd(int fd)
{
  struct Backend_struct *b;
  if((b=get_backend_for_fd(fd)))
    return b;

#ifdef PIKE_DEBUG
  if(!default_backend)
    Pike_fatal("No backend!\n");
#endif
  low_set_backend_for_fd(fd, default_backend);
  return default_backend;
}

/*
 * POLL/SELECT selection
 */

#ifdef HAVE_POLL

struct selectors
{
  struct pollfd *poll_fds;
  int poll_fd_size;
  int num_in_poll;
};

#define active_selectors selectors

#define MY_POLLIN POLLRDNORM|POLLIN
#define MY_POLLOUT POLLOUT

#define MY_POLLEXCEPT POLLRDBAND|POLLRDNORM|POLLIN
#define MY_POLLRDBAND POLLRDBAND
#define MY_POLLWREXCEPT POLLWRBAND|POLLOUT
#define MY_POLLWRBAND POLLWRBAND

#if (POLLRDBAND != POLLRDNORM) && (POLLRDBAND != POLLIN)
#define RDBAND_IS_SPECIAL
#endif

#if  POLLWRBAND != POLLOUT
#define WRBAND_IS_SPECIAL
#endif

  
static void MY_FD_SET(struct selectors *me,
			int fd,
			short add)
{
  int i;
  IF_PD(fprintf(stderr, "BACKEND: MY_FD_SET(%d, 0x%04x)\n", fd, add));
  for(i=0; i<me->num_in_poll; i++)
  {
    if(me->poll_fds[i].fd == fd)
    {
      me->poll_fds[i].events |= add;
      return;
    }
  }
  me->num_in_poll++;
  if (me->num_in_poll > me->poll_fd_size)
  {
    me->poll_fd_size += me->num_in_poll;	/* Usually a doubling */
    if (me->poll_fds) {
      me->poll_fds =
	realloc(me->poll_fds, sizeof(struct pollfd)*me->poll_fd_size);
    } else {
      me->poll_fds = malloc(sizeof(struct pollfd)*me->poll_fd_size);
    }
    if (!me->poll_fds)
    {
      Pike_fatal("Out of memory in backend::MY_FD_SET()\n"
	    "Tried to allocate %d pollfds\n", me->poll_fd_size);
    }
  }
  me->poll_fds[me->num_in_poll-1].fd = fd;
  me->poll_fds[me->num_in_poll-1].events = add;
}

static void MY_FD_CLR(struct selectors *me,
			int fd,
			short sub)
{
  int i;
  IF_PD(fprintf(stderr, "BACKEND: POLL_FD_CLR(%d, 0x%04x)\n", fd, sub));
  if(!me->poll_fds) return;
  for(i=0; i<me->num_in_poll; i++)
  {
    if(me->poll_fds[i].fd == fd)
    {
      me->poll_fds[i].events &= ~sub;
      if(!me->poll_fds[i].events)
      {
	/* Note that num_in_poll is decreased here.
	 * This is to avoid a lot of -1's below.
	 * /grubba
	 */
	me->num_in_poll--;
	if(i != me->num_in_poll)
	{
	  me->poll_fds[i] = me->poll_fds[me->num_in_poll];
	}
	/* Might want to shrink poll_fds here, but probably not. */
      }
      break;
    }
  }
}
  

static void copy_selectors(struct active_selectors *to,
			   struct selectors *from)
{
  IF_PD(fprintf(stderr, "BACKEND: copy_poll_set() from->num_in_poll=%d\n",
		from->num_in_poll));
  
  if (to->poll_fd_size < from->num_in_poll)
  {
    IF_PD(fprintf(stderr, "BACKEND: copy_poll_set() size %d -> %d\n",
		  to->poll_fd_size,
		  from->poll_fd_size));
    to->poll_fd_size=from->poll_fd_size;
    if (to->poll_fds) {
      to->poll_fds =
	realloc(to->poll_fds, sizeof(struct pollfd)*to->poll_fd_size);
    } else {
      to->poll_fds =
	malloc(sizeof(struct pollfd)*to->poll_fd_size);
    }
    if (!to->poll_fds) {
      Pike_fatal("Out of memory in backend::copy_poll_set()\n"
	    "Tried to allocate %d pollfds\n", to->poll_fd_size);
    }
  }
  
  MEMCPY(to->poll_fds,
	 from->poll_fds,
	 sizeof(struct pollfd)*from->num_in_poll);
  to->num_in_poll=from->num_in_poll;
}

#else  /* !HAVE_POLL */


struct selectors
{
  int max_fd;
  my_fd_set read;
  my_fd_set write;
  /* except == incoming OOB data
   * outgoing OOB data is multiplexed on write
   */
  my_fd_set except;
};

struct active_selectors
{
  fd_set rset, wset;
  fd_set eset;
  int max_fd;
};

#define MY_POLLIN &me->set.read
#define MY_POLLOUT &me->set.write

#define MY_POLLEXCEPT &me->set.except
#define MY_POLLRDBAND &me->set.except
#define MY_POLLWREXCEPT &me->set.write
#define MY_POLLWRBAND &me->set.write

#define RDBAND_IS_SPECIAL

#define MY_SELECT(fds,R,W,E,T) fd_select((fds),(R),(W),(E),(T))

void MY_FD_CLR(struct selectors *me, int fd, my_fd_set *s)
{
  if(fd > me->max_fd) return;
  my_FD_CLR(fd, s);
  if(fd == me->max_fd)
  {
    while(me->max_fd >=0 &&
	  !my_FD_ISSET(me->max_fd, &me->read) &&
	  !my_FD_ISSET(me->max_fd, &me->write)
	  && !my_FD_ISSET(me->max_fd, &me->except)
      )
      me->max_fd--;
  }
}

void MY_FD_SET(struct selectors *me, int fd, my_fd_set *s)
{
  my_FD_SET(fd, s);
  if(fd > me->max_fd) me->max_fd=fd;
}

static void copy_selectors(struct active_selectors *to,
			   struct selectors *from)
{
  fd_copy_my_fd_set_to_fd_set(&to->rset, &from->read, from->max_fd+1);
  fd_copy_my_fd_set_to_fd_set(&to->wset, &from->write, from->max_fd+1);
  fd_copy_my_fd_set_to_fd_set(&to->eset, &from->except, from->max_fd+1);
  to->max_fd=from->max_fd;
}

#endif	/* HAVE_POLL */


/*! @module Pike
 */

/*! @class Backend
 */
PIKECLASS Backend
{
  /* Provide a unique count to be able to tell backends apart with _sprintf. */
  static int unused_id = 0;
  CVAR int id;

  /*
   * Backend callbacks
   */
  CVAR struct callback_list backend_callbacks;

  /* Thread currently executing in the backend. */
#ifdef PIKE_THREADS
  CVAR struct thread_state *exec_thread;
#else
  CVAR int exec_thread;		/* 1 if inside the backend. */
#endif

  /*
   * PIPE for waking up
   */
  CVAR int wakeup_pipe[2];

  /*
   * FD callback data
   */
  CVAR struct fd_datum *fds;
  CVAR int fds_size;

  /* 
   * POLL/SELECT fd sets
   */
  CVAR struct selectors set;
  CVAR struct active_selectors active_set;

  /*
   * CALL OUT variables
   */
  CVAR int num_pending_calls;           /* no of busy pointers in buffer */
  CVAR call_out **call_buffer;  /* pointer to buffer */
  CVAR int call_buffer_size;     /* no of pointers in buffer */
  
  CVAR unsigned int hash_size;
  CVAR unsigned int hash_order;
  CVAR struct hash_ent *call_hash;

  /* Should really exist only in PIKE_DEBUG, but 
   * #ifdefs on the last cvar confuses precompile.pike.
   *	/grubba 2001-03-12
   * Should be fixed now -Hubbe
   */
#ifdef PIKE_DEBUG
  CVAR int inside_call_out;
#endif

  /* The object we're in. This ref isn't refcounted. */
  CVAR struct object *backend_obj;

  DECLARE_STORAGE
  /*
   * Call out defines
   */
#undef CAR
#undef CDR

#define CAR(X) (((X)<<1)+1)
#define CDR(X) (((X)<<1)+2)
#define PARENT(X) (((X)-1)>>1)
#define CALL(X) (me->call_buffer[(X)])
#define MOVECALL(X,Y) do { INT32 p_=(X); (CALL(p_)=CALL(Y))->pos=p_; }while(0)
#define CMP(X,Y) my_timercmp(& CALL(X)->tv, <, & CALL(Y)->tv)
#define SWAP(X,Y) do{ call_out *_tmp=CALL(X); (CALL(X)=CALL(Y))->pos=(X); (CALL(Y)=_tmp)->pos=(Y); } while(0)

#ifdef PIKE_DEBUG
#define PROTECT_CALL_OUTS() \
   if(me->inside_call_out) Pike_fatal("Recursive call in call_out module.\n"); \
   me->inside_call_out=1
 
#define UNPROTECT_CALL_OUTS() \
   me->inside_call_out=0
#else /* !PIKE_DEBUG */
#define PROTECT_CALL_OUTS()
#define UNPROTECT_CALL_OUTS()
#endif /* PIKE_DEBUG */


  /* 
   * FDS handling
   */
#define FDS_ISSET(fd,X) (me->fds_size>(fd) &&  me->fds[(fd)].X!=0)
#define ASSURE_FDS_SIZE(ME,X)  do{ 		\
  struct Backend_struct *me_=(ME);		\
  int fd_=(X);					\
  if(fd_ >= me_->fds_size)  grow_fds(ME,X);	\
}while(0)
  
  void grow_fds(struct Backend_struct *me,
		int wanted_size)
    {
      int old_size=me->fds_size;
      debug_malloc_touch(me->fds);
      if(!me->fds_size) me->fds_size = 16;
      while(wanted_size >= me->fds_size) me->fds_size*=2;
      if (me->fds) {
	me->fds = realloc(me->fds, sizeof(struct fd_datum) * me->fds_size);
      } else {
	me->fds = malloc(sizeof(struct fd_datum) * me->fds_size);
      }
      if( !me->fds )
	Pike_fatal("Out of memory in backend::grow_fds()\n"
	      "Tried to allocate %d fd_datum structs\n", me->fds_size);
      MEMSET(me->fds+old_size,
	     0,
	     (me->fds_size-old_size)*sizeof(struct fd_datum));
      debug_malloc_touch(me->fds);
    }


  struct callback *backend_debug_add_backend_callback(struct Backend_struct *me,
						      callback_func call,
						      void *arg,
						      callback_func free_func)
    {
      return add_to_callback(& me->backend_callbacks, call, arg, free_func);
    }
  
  static int wakeup_callback(int fd, void *foo)
    {
      char buffer[1024];
      fd_read(fd, buffer, sizeof(buffer)); /* Clear 'flag' */
      return 0;
    }

  /* This is used by threaded programs and signals to wake up the
   * master 'thread'.
   */
  void backend_wake_up_backend(struct Backend_struct *me)
    {
      char foo=0;

      if(me && me->exec_thread)
	fd_write(me->wakeup_pipe[1], &foo ,1);
    }


  void backend_set_read_callback(struct Backend_struct *me,
				 int fd,
				 file_callback cb,
				 void *data)
    {
      int was_set;
      IF_PD(fprintf(stderr, "BACKEND[%d]: set_read_callback(%d, %p, %p)\n",
		    me->id, fd, cb, data));

      if(!me || (!cb && me->fds_size <= fd)) return;

      debug_malloc_touch(me->fds);
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      was_set = FDS_ISSET(fd, read.callback);
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      me->fds[fd].read.callback=cb;
      me->fds[fd].read.data=data;
      
      if(cb)
      {
#ifdef PIKE_DEBUG
	if (get_backend_for_fd (fd) != me)
	  Pike_fatal ("This backend doesn't own this fd.\n");
#endif
	if(!was_set)
	{
	  MY_FD_SET(&me->set, fd, MY_POLLIN);
	  backend_wake_up_backend(me);
	}
      }else{
	if (was_set) {
	  MY_FD_CLR(&me->set, fd, MY_POLLIN);
#if defined(HAVE_POLL)
	  if (me->fds[fd].read_oob.callback)
          {
            MY_FD_SET(&me->set, fd, MY_POLLEXCEPT);
          }
#endif
        }
      }
    }
  
  void backend_set_write_callback(struct Backend_struct *me,
				  int fd,
				  file_callback cb,
				  void *data)
    {
      int was_set;
      IF_PD(fprintf(stderr, "BACKEND[%d]: set_write_callback(%d, %p, %p)\n",
		    me->id, fd, cb, data));
      
      if(!me || (!cb && me->fds_size <= fd)) return;

      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      was_set = FDS_ISSET(fd, write.callback);
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      
      me->fds[fd].write.callback=cb;
      me->fds[fd].write.data=data;
      
      if(cb)
      {
#ifdef PIKE_DEBUG
	if (get_backend_for_fd (fd) != me)
	  Pike_fatal ("This backend doesn't own this fd.\n");
#endif
	if(!was_set)
	{
	  MY_FD_SET(&me->set, fd, MY_POLLOUT);
	  backend_wake_up_backend(me);
	}
      } else {
	if (was_set
	    && !me->fds[fd].write_oob.callback
	  )
	  MY_FD_CLR(&me->set, fd, MY_POLLOUT);
      }
    }


  void backend_set_read_oob_callback(struct Backend_struct *me,
				     int fd,
				     file_callback cb,
				     void *data)
    {
      int was_set;
      IF_PD(fprintf(stderr, "BACKEND[%d]: set_read_oob_callback(%d, %p, %p)\n",
		    me->id, fd, cb, data));
      
      if(!me || (!cb && me->fds_size <= fd)) return;

      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      was_set = FDS_ISSET(fd, read_oob.callback);
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      me->fds[fd].read_oob.callback=cb;
      me->fds[fd].read_oob.data=data;
      
      if(cb)
      {
#ifdef PIKE_DEBUG
	if (get_backend_for_fd (fd) != me)
	  Pike_fatal ("This backend doesn't own this fd.\n");
#endif
	MY_FD_SET(&me->set, fd, MY_POLLEXCEPT);
	backend_wake_up_backend(me);
      }else{
	if(was_set) {
	  if (!me->fds[fd].read.callback) {
	    MY_FD_CLR(&me->set, fd, MY_POLLEXCEPT);
	  } else {
#ifdef RDBAND_IS_SPECIAL
	    MY_FD_CLR(&me->set, fd, MY_POLLRDBAND);
#endif
	  }
	}
      }
    }
  

  void backend_set_write_oob_callback(struct Backend_struct *me,
				      int fd,
				      file_callback cb,
				      void *data)
    {
      int was_set;
      IF_PD(fprintf(stderr, "BACKEND[%d]: set_write_oob_callback(%d, %p, %p)\n",
		    me->id, fd, cb, data));
      
      if(!me || (!cb && me->fds_size <= fd)) return;

      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      was_set = FDS_ISSET(fd, write_oob.callback);
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      
      me->fds[fd].write_oob.callback=cb;
      me->fds[fd].write_oob.data=data;
      
      if(cb)
      {
#ifdef PIKE_DEBUG
	if (get_backend_for_fd (fd) != me)
	  Pike_fatal ("This backend doesn't own this fd.\n");
#endif
	MY_FD_SET(&me->set, fd, MY_POLLWREXCEPT);
	backend_wake_up_backend(me);
      }else{
	if(was_set) {
	  if (!me->fds[fd].write.callback) {
	    MY_FD_CLR(&me->set, fd, MY_POLLWREXCEPT);
	  } else {
#ifdef WRBAND_IS_SPECIAL
	    MY_FD_CLR(&me->set, fd, MY_POLLWRBAND);
#endif
	  }
	}
      }
    }
  
  file_callback backend_query_read_callback(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_read_callback(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      return me->fds[fd].read.callback;
    }
  
  file_callback backend_query_write_callback(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_write_callback(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      return me->fds[fd].write.callback;
    }

  file_callback backend_query_read_oob_callback(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_read_oob_callback(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      return me->fds[fd].read_oob.callback;
    }
  
  file_callback backend_query_write_oob_callback(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_write_oob_callback(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      return me->fds[fd].write_oob.callback;
    }
  
  void *backend_query_read_callback_data(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_read_callback_data(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      return me->fds[fd].read.data;
    }

  /* FIXME */
  void *backend_query_write_callback_data(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_write_callback_data(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      return me->fds[fd].write.data;
    }

  /* FIXME */
  void *backend_query_read_oob_callback_data(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_read_oob_callback_data(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd );
      debug_malloc_touch(me->fds);
      return me->fds[fd].read_oob.data;
    }

  /* FIXME */
  void *backend_query_write_oob_callback_data(struct Backend_struct *me,int fd)
    {
#ifdef PIKE_DEBUG
      if(fd<0)
	Pike_fatal("File descriptor out of range.\n %d",fd);
#endif
      IF_PD(fprintf(stderr, "BACKEND[%d]: query_write_oob_callback_data(%d)\n", me->id, fd));
      if(!me || (me->fds_size <= fd)) return 0;
      ASSURE_FDS_SIZE(me, fd);
      debug_malloc_touch(me->fds);
      return me->fds[fd].write_oob.data;
    }
  
#ifdef PIKE_DEBUG

  static void backend_do_debug(struct Backend_struct *me)
    {
      int e;
      PIKE_STAT_T tmp;

      backend_verify_call_outs(me);
      
      /* FIXME: OOB? */
#ifndef HAVE_POLL
      for(e=0;e<=me->set.max_fd;e++)
      {
	if(my_FD_ISSET(e, &me->set.read)
	   || my_FD_ISSET(e, &me->set.write)
	   || my_FD_ISSET(e, &me->set.except)
	  )
	{
	  int ret;

	  if (e >= fd_map_size || fd_map[e] != me)
	    Pike_fatal ("Isn't referenced from fd_map for fd %d in select set.\n", e);

	  do {
	    ret = fd_fstat(e, &tmp);
	    /* FIXME: Perhaps do check_threads_etc() here? */
	  }while(ret < 0 && errno == EINTR);

	  if(ret<0)
	  {
	    switch(errno)
	    {
	      case EBADF:
		Pike_fatal("Backend filedescriptor %d is bad.\n",e);
		break;
	      case ENOENT:
		Pike_fatal("Backend filedescriptor %d is not.\n",e);
		break;
	    }
	  }
	}
      }
#else  /* HAVE_POLL */
      for(e=0;e<me->set.num_in_poll;e++)
      {
	int ret;
	int fd = me->set.poll_fds[e].fd;

	if (fd >= fd_map_size || fd_map[fd] != me)
	  Pike_fatal ("Isn't referenced from fd_map for fd %d at %d in poll set.\n",
		      fd, e);

	do {
	  ret=fd_fstat(fd, &tmp);
	  /* FIXME: Perhaps do check_threads_etc() here? */
	}while(ret < 0 && errno == EINTR);

	if(ret<0)
	{
	  switch(errno)
	  {
	    case EBADF:
	      Pike_fatal("Backend filedescriptor %d is bad.\n", fd);
	      break;
	    case ENOENT:
	      Pike_fatal("Backend filedescriptor %d is not.\n", fd);
	      break;
	  }
	}
      }
#endif	/* !HAVE_POLL */
    }
#endif

  static void low_backend_cleanup (struct Backend_struct *me)
  {
    me->exec_thread = 0;
  }

  /* A negative tv_sec in timeout turns it off. If it ran until the
   * timeout without calling any callbacks or call outs (except those
   * on backend_callbacks) then tv_sec will be set to -1. Otherwise it
   * will be set to the time spent. */
  void low_backend_once(struct Backend_struct *me,
			struct timeval *timeout)
    {
      int i, done_something = 0;
      struct timeval start_time;
#ifndef HAVE_POLL
      struct timeval select_timeout;
#endif

      alloca(0);			/* Do garbage collect */
#ifdef PIKE_DEBUG
      if(d_flag > 1) do_debug();
#endif
      
#ifndef OWN_GETHRTIME
      GETTIMEOFDAY(&current_time);
#else
      /* good place to run the gethrtime-conversion update
	 since we have to run gettimeofday anyway /Mirar */
      own_gethrtime_update(&current_time);
#endif
      start_time.tv_sec = current_time.tv_sec;
      start_time.tv_usec = current_time.tv_usec;

      copy_selectors(& me->active_set, &me->set);

      {
	ONERROR uwp;
#ifdef HAVE_POLL
	int poll_msec;
#endif
#ifdef PIKE_DEBUG
	struct timeval max_timeout;
#endif

	if(me->exec_thread) {
#ifdef PIKE_THREADS
	  if (me->exec_thread != Pike_interpreter.thread_state)
	    Pike_error ("Backend already in use by another thread.\n");
	  else
#endif
	    /* It's actually not a problem to support reentrancy, but I
	     * can't think of any sane way to use it. Otoh, this error
	     * can help discover otherwise tricky bugs. /mast */
	    Pike_error ("Backend already running - cannot reenter.\n");
	}
#ifdef PIKE_THREADS
	me->exec_thread = Pike_interpreter.thread_state;
#else
	me->exec_thread = 1;
#endif
	SET_ONERROR (uwp, low_backend_cleanup, me);

	if (timeout->tv_sec < 0) {
	  next_timeout.tv_sec = 100000000;
	  next_timeout.tv_usec = 999999;
	}
	else {
	  next_timeout.tv_sec = timeout->tv_sec;
	  next_timeout.tv_usec = timeout->tv_usec;
	  my_add_timeval(&next_timeout, &current_time);
	}

	/* Call outs */
	if(me->num_pending_calls)
	  if(my_timercmp(& CALL(0)->tv, < , &next_timeout))
	    next_timeout = CALL(0)->tv;

#ifdef PIKE_DEBUG
	max_timeout = next_timeout;
#endif
	call_callback(& me->backend_callbacks, NULL);
#ifdef PIKE_DEBUG
	if (my_timercmp (&max_timeout, <, &next_timeout))
	  Pike_fatal ("Timeout raised from %ld.%ld to %ld.%ld by a backend callback.\n",
		      max_timeout.tv_sec, max_timeout.tv_usec,
		      next_timeout.tv_sec, next_timeout.tv_usec);
#endif

	if(my_timercmp(&next_timeout, > , &current_time))
	{
	  my_subtract_timeval(&next_timeout, &current_time);
	}else{
	  next_timeout.tv_usec = 0;
	  next_timeout.tv_sec = 0;
	}

#ifdef HAVE_POLL
	if (next_timeout.tv_sec >= 100000000)
	  /* Take this as waiting forever. */
	  poll_msec = -1;
	else if(next_timeout.tv_sec < 0)
	  poll_msec=0;
	else if(next_timeout.tv_sec > (INT_MAX/1002))
	  poll_msec=INT_MAX;
	else
	  poll_msec= (next_timeout.tv_sec*1000) +
	    next_timeout.tv_usec/1000;
#else  /* !HAVE_POLL */
	select_timeout = next_timeout;
#endif

#if defined (HAVE_POLL) && defined (POLL_DEBUG)
	fprintf (stderr, "BACKEND[%d]: Doing poll on fds:\n", me->id);
	{
	  int i;
	  for (i = 0; i < me->active_set.num_in_poll; i++) {
	    fprintf (stderr,
		     "BACKEND[%d]:   fd %4d: %-4s %-5s %-8s %-9s\n",
		     me->id,
		     me->active_set.poll_fds[i].fd,
		     me->active_set.poll_fds[i].events & (POLLRDNORM|POLLIN) ? "read" : "",
		     me->active_set.poll_fds[i].events & POLLOUT ? "write" : "",
		     me->active_set.poll_fds[i].events & POLLRDBAND ? "read_oob" : "",
		     me->active_set.poll_fds[i].events & POLLWRBAND ? "write_oob" : "");
	  }
	}
	fprintf(stderr, "BACKEND[%d]: poll(%p, %d, %d)...", me->id,
		me->active_set.poll_fds,
		me->active_set.num_in_poll,
		poll_msec);
#endif	/* defined (HAVE_POLL) && defined (POLL_DEBUG) */

	THREADS_ALLOW();

#ifdef HAVE_POLL
	i = poll(me->active_set.poll_fds,
		 me->active_set.num_in_poll,
		 poll_msec);
	IF_PD(fprintf(stderr, " => %d\n", i));
#else  /* !HAVE_POLL */
	i = MY_SELECT(me->active_set.max_fd+1,
		      &me->active_set.rset,
		      &me->active_set.wset, 
		      &me->active_set.eset,
		      select_timeout.tv_sec >= 100000000 ?
		      NULL : &select_timeout);
#endif	/* HAVE_POLL */

	THREADS_DISALLOW();

	me->exec_thread = 0;
	UNSET_ONERROR (uwp);

	GETTIMEOFDAY(&current_time);
      }

      if (!i) {
	/* Timeout */
      } else if (i>0) {
#ifdef PIKE_DEBUG
	int num_active = i;
#endif /* PIKE_DEBUG */
	done_something = 1;

#ifndef HAVE_POLL
	/* FIXME: OOB? */
	debug_malloc_touch(me->fds);
	for(i=0; i <= me->active_set.max_fd; i++)
	{
	  /* FIXME: Error handling equivalent to POLLHUP/POLLERR? */

	  if(fd_FD_ISSET(i, &me->active_set.eset) &&
	     me->fds[i].read_oob.callback)
	    if ((*(me->fds[i].read_oob.callback))(i, me->fds[i].read_oob.data) == -1)
	      goto callbacks_done;
	  
	  if(fd_FD_ISSET(i, &me->active_set.rset) && me->fds[i].read.callback)
	    if ((*(me->fds[i].read.callback))(i, me->fds[i].read.data) == -1)
	      goto callbacks_done;
	  
	  if(fd_FD_ISSET(i, &me->active_set.wset)) {
	    if (me->fds[i].write_oob.callback) {
	      if ((*(me->fds[i].write_oob.callback))(i, me->fds[i].write_oob.data) == -1)
		goto callbacks_done;
	    } else
	      if (me->fds[i].write.callback) {
		if ((*(me->fds[i].write.callback))(i, me->fds[i].write.data) == -1)
		  goto callbacks_done;
	      }
	  }
	}
#else  /* HAVE_POLL */
	for(i=0; i<me->active_set.num_in_poll; i++)
	{
	  int fd = me->active_set.poll_fds[i].fd;
#ifdef PIKE_DEBUG
	  int handled = 0;
#endif /* PIKE_DEBUG */
	  if(me->active_set.poll_fds[i].revents & POLLNVAL)
	  {
	    int j;
	    for(j=0;j<me->set.num_in_poll;j++)
	    {
	      if(me->set.poll_fds[j].fd == fd) /* It's still there... */
	      {
		struct pollfd fds;
		int ret;
		fds.fd=fd;
		fds.events=POLLIN;
		fds.revents=0;
		ret=poll(&fds, 1,1 );
		if(fds.revents & POLLNVAL)
		  Pike_fatal("Bad filedescriptor %d to poll().\n", fd);
		break;
	      }
	    }
#ifdef PIKE_DEBUG
	    handled = 1;
#endif /* PIKE_DEBUG */
	  }
	  
	  if (me->active_set.poll_fds[i].revents & POLLRDBAND) {
	    IF_PD(fprintf(stderr, "BACKEND[%d]: POLLRDBAND on %d\n", me->id, fd));
	    if (me->fds[fd].read_oob.callback)
	    {
	      errno = 0;
	      IF_PD(fprintf(stderr, "BACKEND[%d]: read_oob_callback(%d, %p)\n",
			    me->id, fd, me->fds[fd].read_oob.data));
	      if ((*(me->fds[fd].read_oob.callback))(fd, me->fds[fd].read_oob.data) == -1)
		goto callbacks_done;
	    }
	    else {
	      if (!me->fds[fd].read.callback) {
		MY_FD_CLR(&me->set, fd, MY_POLLEXCEPT);
	      } else {
#ifdef RDBAND_IS_SPECIAL
		MY_FD_CLR(&me->set, fd, MY_POLLRDBAND);
#endif
	      }
	    }
#ifdef PIKE_DEBUG
	    handled = 1;
#endif /* PIKE_DEBUG */
	  }
	  
	  if((me->active_set.poll_fds[i].revents & POLLHUP) ||
	     (me->active_set.poll_fds[i].revents & POLLERR))
	  {
	    /* Closed or error */
	    errno = 0;
	    if (me->active_set.poll_fds[i].revents & POLLERR) {
	      int err;
	      ACCEPT_SIZE_T len = sizeof (err);
	      if (!getsockopt (fd, SOL_SOCKET, SO_ERROR, &err, &len)) {
		IF_PD (fprintf (stderr, "BACKEND[%d]: POLLERR on %d, error=%d\n",
				me->id, fd, err));
		errno = err;
	      }
#ifdef PIKE_DEBUG
	      else
		fprintf(stderr, "Got POLLERR on non-socket fd %d (getsockopt errno=%d)\n",
			fd, errno);
#endif /* PIKE_DEBUG */
	    }
	    else {
	      IF_PD(fprintf(stderr, "BACKEND[%d]: POLLHUP on %d\n", me->id, fd));
	    }
	    /* We don't want to keep this fd anymore. */
	    MY_FD_CLR(&me->set, fd, ~0);
	    if (me->fds[fd].read.callback) {
	      IF_PD(fprintf(stderr, "BACKEND[%d]: read_callback(%d, %p)\n",
			    me->id, fd, me->fds[fd].read.data));
	      if ((*(me->fds[fd].read.callback))(fd,me->fds[fd].read.data) == -1)
		goto callbacks_done;
	    } else if (me->fds[fd].write.callback) {
	      IF_PD(fprintf(stderr, "BACKEND[%d]: write_callback(%d, %p)\n",
			    me->id, fd, me->fds[fd].write.data));
	      if ((*(me->fds[fd].write.callback))(fd, me->fds[fd].write.data) == -1)
		goto callbacks_done;
	    }
#ifdef PIKE_DEBUG
	    handled = 1;
#endif /* PIKE_DEBUG */
	  }
	  
	  if(me->active_set.poll_fds[i].revents & (POLLRDNORM|POLLIN))
	  {
	    IF_PD(fprintf(stderr, "BACKEND[%d]: POLLRDNORM|POLLIN on %d\n", me->id, fd));
	    if (me->fds[fd].read.callback) {
	      IF_PD(fprintf(stderr, "BACKEND[%d]: read_callback(%d, %p)\n",
			    me->id, fd, me->fds[fd].read.data));
	      errno = 0;
	      if ((*(me->fds[fd].read.callback))(fd,me->fds[fd].read.data) == -1)
		goto callbacks_done;
	    } else {
	      MY_FD_CLR(&me->set, fd, POLLRDNORM|POLLIN);
	    }
#ifdef PIKE_DEBUG
	    handled = 1;
#endif /* PIKE_DEBUG */
	  }
	  
	  if (me->active_set.poll_fds[i].revents & POLLWRBAND) {
	    IF_PD(fprintf(stderr, "BACKEND[%d]: POLLWRBAND on %d\n", me->id, fd));
	    if (me->fds[fd].write_oob.callback) {
	      IF_PD(fprintf(stderr, "BACKEND[%d]: write_oob_callback(%d, %p)\n",
			    me->id, fd, me->fds[fd].write_oob.data));
	      errno = 0;
	      if ((*(me->fds[fd].write_oob.callback))(fd, me->fds[fd].write_oob.data) == -1)
		goto callbacks_done;
	    }
	    else {
	      if (!me->fds[fd].write.callback) {
		MY_FD_CLR(&me->set, fd, MY_POLLWREXCEPT);
	      } else {
#ifdef WRBAND_IS_SPECIAL
		MY_FD_CLR(&me->set, fd, MY_POLLWRBAND);
#endif
	      }
	    }
#ifdef PIKE_DEBUG
	    handled = 1;
#endif /* PIKE_DEBUG */
	  }
	  
	  if(me->active_set.poll_fds[i].revents & POLLOUT) {
	    IF_PD(fprintf(stderr, "BACKEND[%d]: POLLOUT on %d\n", me->id, fd));
	    if (me->fds[fd].write.callback) {
	      IF_PD(fprintf(stderr, "BACKEND[%d]: write_callback(%d, %p)\n",
			    me->id, fd, me->fds[fd].write.data));
	      errno = 0;
	      if ((*(me->fds[fd].write.callback))(fd, me->fds[fd].write.data) == -1)
		goto callbacks_done;
	    } else {
	      MY_FD_CLR(&me->set, fd, POLLOUT);
	    }
#ifdef PIKE_DEBUG
	    handled = 1;
#endif /* PIKE_DEBUG */
	  }
#ifdef PIKE_DEBUG
	  num_active -= handled;
	  if (!handled && me->active_set.poll_fds[i].revents) {
	    fprintf(stderr, "BACKEND[%d]: fd %ld has revents 0x%08lx, "
		    "but hasn't been handled.\n", me->id,
		    (long)me->active_set.poll_fds[i].fd,
		    (long)me->active_set.poll_fds[i].revents);
	  }
#endif /* PIKE_DEBUG */
	}
#ifdef PIKE_DEBUG
	if (num_active) {
	  fprintf(stderr, "BACKEND[%d]: %d more active fds than were handled.\n",
		  me->id, num_active);
	  for(i=0; i<me->active_set.num_in_poll; i++) {
	    fprintf(stderr, "BACKEND[%d]: fd %ld, events 0x%08lx, revents 0x%08lx\n",
		    me->id,
		    (long)me->active_set.poll_fds[i].fd,
		    (long)me->active_set.poll_fds[i].events,
		    (long)me->active_set.poll_fds[i].revents);
	  }
	}
#endif /* PIKE_DEBUG */
#endif	/* HAVE_POLL */

      callbacks_done:
	/* Must be up-to-date for backend_do_call_outs. */
	GETTIMEOFDAY(&current_time);
      }else{
	switch(errno)
	{
#ifdef __NT__
	  default:
	    Pike_fatal("Error in backend %d\n",errno);
	    break;
#endif
	    
	  case EINVAL:
	    Pike_fatal("Invalid timeout to select().\n");
	    break;
	    
#ifdef WSAEINTR
	  case WSAEINTR:
#endif
	  case EINTR:		/* ignore */
	    break;
	    
#ifdef WSAEBADF
	  case WSAEBADF:
#endif
#ifdef WSAENOTSOCK
	  case WSAENOTSOCK:
#endif
	  case EBADF:
	    /* TODO: Fix poll version! */
#ifndef HAVE_POLL
	    copy_selectors(& me->active_set, &me->set);

	    select_timeout.tv_usec=0;
	    select_timeout.tv_sec=0;
	    if(MY_SELECT(me->active_set.max_fd+1,
			 &me->active_set.rset,
			 &me->active_set.wset, 
			 &me->active_set.eset,
			 &select_timeout) < 0)
	    {
	      switch(errno)
	      {
#ifdef WSAEBADF
		case WSAEBADF:
#endif
#ifdef WSAENOTSOCK
		case WSAENOTSOCK:
#endif
		case EBADF:
		{
		  int i;
		  for(i=0;i<me->fds_size;i++)
		  {
		    if(!my_FD_ISSET(i, &me->set.read) &&
		       !my_FD_ISSET(i, &me->set.write)
		       && !my_FD_ISSET(i, &me->set.except)
		      )
		      continue;
		    
		    fd_FD_ZERO(& me->active_set.rset);
		    fd_FD_ZERO(& me->active_set.wset);
		    fd_FD_ZERO(& me->active_set.eset);
		    
		    if(my_FD_ISSET(i, &me->set.read))
		      fd_FD_SET(i, & me->active_set.rset);
		    if(my_FD_ISSET(i, &me->set.write))
		      fd_FD_SET(i, & me->active_set.wset);
		    if(my_FD_ISSET(i, &me->set.except))
		      fd_FD_SET(i, & me->active_set.eset);
		    
		    select_timeout.tv_usec=0;
		    select_timeout.tv_sec=0;
		    
		    if(MY_SELECT(me->active_set.max_fd+1,
				 &me->active_set.rset,
				 &me->active_set.wset, 
				 &me->active_set.eset,
				 &select_timeout) < 0)
		    {
		      switch(errno)
		      {
#ifdef __NT__
			default:
#endif
			case EBADF:
#ifdef WSAEBADF
			case WSAEBADF:
#endif
#ifdef WSAENOTSOCK
			case WSAENOTSOCK:
#endif

#ifdef DEBUG_MALLOC
			  debug_malloc_dump_fd(i);
#endif
			  Pike_fatal("Filedescriptor %d (%s) caused fatal error %d in backend.\n",i,fd_info(i),errno);
			  
			case EINTR:
			  break;
		      }
		    }
		  }
		}
	      }
#ifdef _REENTRANT
	      /* FIXME: Extra stderr messages should not be allowed.../Hubbe */
	      write_to_stderr("Bad filedescriptor to select().\n"
			      "fd closed in another thread?\n", 62);
#else /* !_REENTRANT */
	      Pike_fatal("Bad filedescriptor to select().\n");
#endif /* _REENTRANT */
	    }
#endif	/* HAVE_POLL */
	    break;
	    
	}
      }

      done_something +=
	backend_do_call_outs(me); /* Will update current_time after calls. */

      call_callback(& me->backend_callbacks, (void *)(ptrdiff_t)1);

      if (!done_something)
	timeout->tv_sec = -1;
      else {
	timeout->tv_sec = current_time.tv_sec;
	timeout->tv_usec = current_time.tv_usec;
	my_subtract_timeval (timeout, &start_time);
      }
    }

  /*! @decl float|int(0..0) `()(void|float|int(0..0) sleep_time)
   *!   Perform one pass through the backend.
   *!
   *! @param sleep_time
   *!   Wait at most @[sleep_time] seconds. The default when
   *!   unspecified or the integer @expr{0@} is no time limit.
   *!
   *! @returns
   *!   If the backend did call any callbacks or call outs then the
   *!   time spent in the backend is returned. Otherwise the integer
   *!   @expr{0@} is returned.
   */
  PIKEFUN float|int(0..0) `()(void|float|int(0..0) sleep_time)
  {
    struct timeval timeout;

    if (sleep_time && sleep_time->type == PIKE_T_FLOAT) {
      timeout.tv_sec = (long) floor (sleep_time->u.float_number);
      timeout.tv_usec =
	(long) ((sleep_time->u.float_number - timeout.tv_sec) * 1e6);
    }
    else
      timeout.tv_sec = -1;
    pop_n_elems (args);

    low_backend_once(THIS, &timeout);

    if (timeout.tv_sec < 0)
      push_int (0);
    else
      push_float ((float) timeout.tv_sec + (float) timeout.tv_usec / 1e6);
  }

  /*! @decl Thread.Thread executing_thread()
   *! @decl int executing_thread()
   *!
   *! Return the thread currently executing in the backend. I.e. the
   *! thread that has called @[`()] and haven't exited from that call.
   *! Zero is returned if there's no thread in the backend.
   *!
   *! If Pike is compiled without thread support then @expr{1@} is
   *! returned if we're inside the backend, @expr{0@} otherwise.
   */
  PIKEFUN object(Thread.Thread)|int(0..1) executing_thread()
    /* FIXME: The type is too weak, but precompile.pike doesn't
     * understand different function variants in cpp branches. */
  {
    pop_n_elems (args);
#ifdef PIKE_THREADS
    if (THIS->exec_thread)
      ref_push_object (THIS->exec_thread->thread_obj);
    else
      push_int (0);
#else
    push_int (THIS->exec_thread);
#endif
  }

  /*! @decl void add_file(Stdio.File|Stdio.FILE f)
   *! 
   *! Add @[f] to this backend. This simply does
   *! @expr{f->set_backend(backend)@} where @expr{backend@} is this
   *! object.
   */
  PIKEFUN void add_file(object f)
  {
    ref_push_object (Pike_fp->current_object);
    apply (f, "set_backend", 1);
    pop_stack();
  }


  /* CALL OUT */

#ifdef PIKE_DEBUG
 
 static void backend_verify_call_outs(struct Backend_struct *me)
   {
     struct array *v;
     int e,d;
     
     if(!d_flag) return;
     if(!me->call_buffer) return;

     if(me->num_pending_calls<0 || me->num_pending_calls>me->call_buffer_size)
       Pike_fatal("Error in call out tables.\n");

     if(d_flag<2) return;

     for(e=0;e<me->num_pending_calls;e++)
     {
       if(e)
       {
	 if(CMP(e, PARENT(e)))
	   Pike_fatal("Error in call out heap. (@ %d)\n",e);
       }

       if(!(v=CALL(e)->args))
	 Pike_fatal("No arguments to call.\n");

       if(v->refs < 1)
	 Pike_fatal("Array should have at least one reference.\n");
       
       if(v->malloced_size<v->size)
	 Pike_fatal("Impossible array.\n");
       
       if(!v->size)
	 Pike_fatal("Call out array of zero size!\n");
       
       if(CALL(e)->prev_arr[0] != CALL(e))
	 Pike_fatal("call_out[%d]->prev_arr[0] is wrong!\n",e);
       
       if(CALL(e)->prev_fun[0] != CALL(e))
	 Pike_fatal("call_out[%d]->prev_fun[0] is wrong!\n",e);
       
       if(CALL(e)->pos != e)
	 Pike_fatal("Call_out->pos is not correct!\n");

       if(d_flag>4)
       {
	 for(d=e+1;d<me->num_pending_calls;d++)
	   if(CALL(e)->args == CALL(d)->args)
	     Pike_fatal("Duplicate call out in heap.\n");
       }
     }
     
     for(d=0;d<10 && e<me->call_buffer_size;d++,e++)
       CALL(e)=(call_out *)(ptrdiff_t)-1;

     for(e=0;e<(int)me->hash_size;e++)
     {
       call_out *c,**prev;
       for(prev=& me->call_hash[e].arr;(c=*prev);prev=& c->next_arr)
       {
	 if(c->prev_arr != prev)
	   Pike_fatal("c->prev_arr is wrong %p.\n",c);

	 if(c->pos<0)
	   Pike_fatal("Free call_out in call_out hash table %p.\n",c);
       }

       for(prev=& me->call_hash[e].fun;(c=*prev);prev=& c->next_fun)
       {
	 if(c->prev_fun != prev)
	   Pike_fatal("c->prev_fun is wrong %p.\n",c);
	 
	 if(c->pos<0)
	   Pike_fatal("Free call_out in call_out hash table %p.\n",c);
       }
     }
   }


#else
#define backend_verify_call_outs(X)
#endif


 static void adjust_down(struct Backend_struct *me,int pos)
   {
     while(1)
     {
       int a=CAR(pos), b=CDR(pos);
       if(a >= me->num_pending_calls) break;
       if(b < me->num_pending_calls)
	 if(CMP(b, a))
	   a=b;
       
       if(CMP(pos, a)) break;
       SWAP(pos, a);
       pos=a;
     }
   }
 
 static int adjust_up(struct Backend_struct *me,int pos)
   {
     int parent=PARENT(pos);
     int from;
#ifdef PIKE_DEBUG
     if(pos <0 || pos>=me->num_pending_calls)
       Pike_fatal("Bad argument to adjust_up(%d)\n",pos);
#endif
     if(!pos) return 0;
     
     if(CMP(pos, parent))
     {
       SWAP(pos, parent);
       from=pos;
       pos=parent;
       while(pos && CMP(pos, PARENT(pos)))
       {
	 parent=PARENT(pos);
	 SWAP(pos, parent);
	 from=pos;
	 pos=parent;
       }
       from+=from&1 ? 1 : -1;
       if(from < me->num_pending_calls && CMP(from, pos))
       {
	 SWAP(from, pos);
	 adjust_down(me,from);
       }
       return 1;
     }
     return 0;
   }
 
 static void adjust(struct Backend_struct *me,int pos)
   {
     if(!adjust_up(me,pos)) adjust_down(me,pos);
   }
 
/* start a new call out, return 1 for success */
 static struct array * new_call_out(struct Backend_struct *me,
				    int num_arg,
				    struct svalue *argp)
   {
     call_out *new;
     struct array *args;
     size_t hval;
     
     PROTECT_CALL_OUTS();
     if(me->num_pending_calls==me->call_buffer_size)
     {
       /* here we need to allocate space for more pointers */
       call_out **new_buffer;

       if(!me->call_buffer)
       {
	 me->call_buffer_size=128;
	 me->call_buffer=(call_out **)xalloc(sizeof(call_out *)*me->call_buffer_size);
	 if(!me->call_buffer) return 0;
	 me->num_pending_calls=0;
	 
	 me->hash_size=hashprimes[me->hash_order];
	 me->call_hash=(struct hash_ent *)xalloc(sizeof(struct hash_ent)*me->hash_size);
	 MEMSET(me->call_hash, 0, sizeof(struct hash_ent)*me->hash_size);
       }else{
	 struct hash_ent *new_hash;
	 int e;
	 
	 if (me->call_buffer) {
	   new_buffer = (call_out **)
	     realloc((char *)me->call_buffer,
		     sizeof(call_out *)*me->call_buffer_size*2);
	 } else {
	   new_buffer = (call_out **)
	     malloc(sizeof(call_out *)*me->call_buffer_size*2);
	 }
	 if(!new_buffer)
	   Pike_error("Not enough memory for another call_out\n");
	 me->call_buffer_size*=2;
	 me->call_buffer=new_buffer;

	 if((new_hash=(struct hash_ent *)malloc(sizeof(struct hash_ent)*
						hashprimes[me->hash_order+1])))
	 {
	   free((char *)me->call_hash);
	   me->call_hash=new_hash;
	   me->hash_size=hashprimes[++me->hash_order];
	   MEMSET(me->call_hash, 0, sizeof(struct hash_ent)*me->hash_size);

	   /* Re-hash */
	   for(e=0;e<me->num_pending_calls;e++)
	   {
	     call_out *c=CALL(e);
	     hval=PTR_TO_INT(c->args);

#define LINK(X,c)							\
	     hval%=me->hash_size;					\
	     if((c->PIKE_CONCAT(next_,X)=me->call_hash[hval].X))	\
	       c->PIKE_CONCAT(next_,X)->PIKE_CONCAT(prev_,X)=		\
		 &c->PIKE_CONCAT(next_,X);				\
	     c->PIKE_CONCAT(prev_,X)=&me->call_hash[hval].X;		\
	     me->call_hash[hval].X=c;
	     

	     LINK(arr,c);
	     hval=hash_svalue(c->args->item);
	     LINK(fun,c);
	   }
	 }
       }
     }

     /* time to allocate a new call_out struct */
     args=aggregate_array(num_arg-1);
     
     CALL(me->num_pending_calls)=new=alloc_call_out_s();
     new->pos=me->num_pending_calls;
     
     {
       hval=PTR_TO_INT(args);
       LINK(arr,new);
       hval=hash_svalue(args->item);
       LINK(fun,new);
     }
     
     switch(argp[0].type)
     {
       case T_INT:
	 new->tv.tv_sec=argp[0].u.integer;
	 new->tv.tv_usec=0;
	 break;
	 
       case T_FLOAT:
       {
	 FLOAT_TYPE tmp=argp[0].u.float_number;
	 new->tv.tv_sec = DO_NOT_WARN((long)floor(tmp));
	 new->tv.tv_usec = DO_NOT_WARN((long)(1000000.0 * (tmp - floor(tmp))));
	 break;
       }
       
       default:
	 Pike_fatal("Bad timeout to new_call_out!\n");
     }
     
#ifdef _REENTRANT
     if(num_threads>1)
     {
       struct timeval tmp;
       GETTIMEOFDAY(&tmp);
       my_add_timeval(& new->tv, &tmp);
     }else
#endif
       my_add_timeval(& new->tv, &current_time);
     
     if(Pike_fp && Pike_fp->current_object)
     {
       add_ref(new->caller=Pike_fp->current_object);
     }else{
       new->caller=0;
     }
     
     new->args=args;
     Pike_sp--;
     dmalloc_touch_svalue(Pike_sp);
     
     
     me->num_pending_calls++;
     adjust_up(me, me->num_pending_calls-1);
     backend_verify_call_outs(me);
     
#ifdef _REENTRANT
     backend_wake_up_backend(me);
#endif
     
     UNPROTECT_CALL_OUTS();
     return args;
   }


 /* FIXME add a global function for this? */
 static void backend_count_memory_in_call_outs(struct Backend_struct *me,
				       struct callback *foo,
				       void *bar,
				       void *gazonk)
   {
     push_text("num_call_outs");
     push_int(me->num_pending_calls);
     push_text("call_out_bytes");
     
     push_int64(me->call_buffer_size * sizeof(call_out **)+
		me->num_pending_calls * sizeof(call_out));
   }

   /* FIXME */
#if 0
   MARK 
     {
       int e;
       struct Backend_struct *me=THIS;
       
       for(e=0;e<me->num_pending_calls;e++)
       {
	 gc_mark(CALL(e)->args,0,"call out args");
	 if(CALL(e)->caller)
	   gc_mark(CALL(e)->caller,0,"call out caller");
       }
     }
#endif

/*! @decl mixed call_out(function f, float|int delay, mixed ... args)
 *!
 *! Make a delayed call to a function.
 *!
 *! @[call_out()] places a call to the function @[f] with the argument
 *! @[args] in a queue to be called in about @[delay] seconds.
 *!
 *! If @[f] returns @expr{-1@}, no other call out or callback will be
 *! called by the backend in this round. I.e. @[`()] will return right
 *! away. For the main backend that means it will immediately start
 *! another round and check files and call outs anew.
 *!
 *! @returns
 *!   Returns a call_out identifier that identifies this call_out.
 *!   This value can be sent to eg @[find_call_out()] or @[remove_call_out()].
 *!
 *! @seealso
 *!   @[remove_call_out()], @[find_call_out()], @[call_out_info()]
 */
   PIKEFUN mixed call_out(mixed f, int|float t, mixed ... rest)
     {
       struct svalue tmp;
       struct array *v;
       if(args<2)
	 SIMPLE_TOO_FEW_ARGS_ERROR("call_out", 2);

       if(t->type != T_INT && t->type != T_FLOAT)
	 SIMPLE_BAD_ARG_ERROR("call_out", 2, "int|float");

       /* Swap, for compatibility */
       tmp = Pike_sp[-args];
       Pike_sp[-args] = Pike_sp[1-args];
       Pike_sp[1-args] = tmp;
       
       v = new_call_out(THIS, args, Pike_sp-args);
       ref_push_array(v);
     }

   /* Assumes current_time is correct on entry. */
   int backend_do_call_outs(struct Backend_struct *me)
     {
       int call_count = 0;
       int args;
       struct timeval tmp;
       backend_verify_call_outs(me);

       tmp.tv_sec = current_time.tv_sec;
       tmp.tv_usec = current_time.tv_usec;
       tmp.tv_sec++;
       while(me->num_pending_calls &&
	     my_timercmp(&CALL(0)->tv, <= ,&current_time))
       {
	 /* unlink call out */
	 call_out c,*cc;
	 
	 PROTECT_CALL_OUTS();
	 cc=CALL(0);
	 if(--me->num_pending_calls)
	 {
	   MOVECALL(0,me->num_pending_calls);
	   adjust_down(me, 0);
	 }
	 UNPROTECT_CALL_OUTS();
	 c=*cc;
	 really_free_call_out_s(cc);
	 
	 if(c.caller) free_object(c.caller);
	 
	 args=c.args->size;
	 push_array_items(c.args);
	 check_destructed(Pike_sp - args);
	 if(Pike_sp[-args].type!=T_INT)
	 {
	   call_count++;
	   f_call_function(args);
	   if (Pike_sp[-1].type == T_INT && Pike_sp[-1].u.integer == -1) {
	     pop_stack();
	     backend_verify_call_outs(me);
	     break;
	   }
	   else
	     pop_stack();
	 }else{
	   pop_n_elems(args);
	 }
	 backend_verify_call_outs(me);
	 
	 GETTIMEOFDAY(&current_time);
	 if(my_timercmp(&current_time, > , &tmp)) break;
       }
       return call_count;
     }


   static int backend_find_call_out(struct Backend_struct *me,
				    struct svalue *fun)
     {
       size_t hval;
       call_out *c;
       
       if(!me->num_pending_calls) return -1;
       
       if(fun->type == T_ARRAY)
       {
	 hval=PTR_TO_INT(fun->u.array);
	 hval%=me->hash_size;
	 for(c=me->call_hash[hval].arr;c;c=c->next_arr)
	 {
	   if(c->args == fun->u.array)
	   {
#ifdef PIKE_DEBUG
	     if(CALL(c->pos) != c)
	       Pike_fatal("Call_out->pos not correct!\n");
#endif
	     return c->pos;
	   }
	 }
       }
       
       hval=hash_svalue(fun);
       hval%=me->hash_size;
       for(c=me->call_hash[hval].fun;c;c=c->next_fun)
       {
	 if(is_eq(fun, ITEM(c->args)))
	 {
#ifdef PIKE_DEBUG
	   if(CALL(c->pos) != c)
	     Pike_fatal("Call_out->pos not correct!\n");
#endif
	   return c->pos;
	 }
       }
       return -1;
     }


/*! @decl void _do_call_outs()
 *!
 *! Do all pending call_outs.
 *!
 *! This function runs all pending call_outs that should have been
 *! run if Pike returned to the backend.  It should not be used in
 *! normal operation.
 *!
 *! As a side-effect, this function sets the value returned by
 *! @[time(1)] to the current time.
 *!
 *! @seealso
 *! @[call_out()], @[find_call_out()], @[remove_call_out()]
 */
   PIKEFUN void _do_call_outs()
     {
       GETTIMEOFDAY(&current_time);
       backend_do_call_outs(THIS);
     }

/*! @decl int find_call_out(function f)
 *! @decl int find_call_out(mixed id)
 *!
 *! Find a call out in the queue.
 *!
 *! This function searches the call out queue. If given a function as
 *! argument, it looks for the first call out scheduled to that function.
 *!
 *! The argument can also be a call out id as returned by @[call_out()], in
 *! which case that call_out will be found (Unless it has already been
 *! called).
 *!
 *! @returns
 *!   @[find_call_out()] returns the remaining time in seconds before that
 *!   call_out will be executed. If no call_out is found,
 *!   @[zero_type](@[find_call_out](f)) will return 1.
 *!
 *! @seealso
 *!   @[call_out()], @[remove_call_out()], @[call_out_info()]
 */
   PIKEFUN int find_call_out(function|mixed f)
     {
       struct Backend_struct *me=THIS;
       int e;
       backend_verify_call_outs(me);

       PROTECT_CALL_OUTS();
       e=backend_find_call_out(me, f);
       pop_n_elems(args);
       if(e==-1)
       {
	 Pike_sp->type = T_INT;
	 Pike_sp->subtype = NUMBER_UNDEFINED;
	 Pike_sp->u.integer=-1;
	 Pike_sp++;
       }else{
	 push_int(CALL(e)->tv.tv_sec - current_time.tv_sec);
       }
       UNPROTECT_CALL_OUTS();
       backend_verify_call_outs(me);
     }

/*! @decl int remove_call_out(function f)
 *! @decl int remove_call_out(function id)
 *!
 *! Remove a call out from the call out queue.
 *!
 *! This function finds the first call to the function @[f] in the call_out
 *! queue and removes it.  You can also give a call out id as argument (as
 *! returned by call_out).
 *!
 *! @returns
 *!   The remaining time in seconds left to that call out will be returned.
 *!   If no call_out was found, @[zero_type](@[remove_call_out](@[f]))
 *!   will return 1.
 *!
 *! @seealso
 *!   @[call_out_info()], @[call_out()], @[find_call_out()]
 */
   PIKEFUN int remove_call_out(function|mixed f)
     {
       struct Backend_struct *me=THIS;
       int e;
       PROTECT_CALL_OUTS();
       backend_verify_call_outs(me);
       e=backend_find_call_out(me,f);
       backend_verify_call_outs(me);
       if(e!=-1)
       {
	 pop_n_elems(args);
	 push_int(CALL(e)->tv.tv_sec - current_time.tv_sec);
	 free_array(CALL(e)->args);
	 if(CALL(e)->caller)
	   free_object(CALL(e)->caller);
	 really_free_call_out_s(CALL(e));
	 me->num_pending_calls--;
	 if(e!=me->num_pending_calls)
	 {
	   MOVECALL(e,me->num_pending_calls);
	   adjust(me,e);
	 }
       }else{
	 pop_n_elems(args);
	 Pike_sp->type = T_INT;
	 Pike_sp->subtype = NUMBER_UNDEFINED;
	 Pike_sp->u.integer = -1;
	 Pike_sp++;
       }
       backend_verify_call_outs(me);
       UNPROTECT_CALL_OUTS();
     }

/* return an array containing info about all call outs:
 * ({  ({ delay, caller, function, args, ... }), ... })
 */
   struct array *backend_get_all_call_outs(struct Backend_struct *me)
     {
       int e;
       struct array *ret;

       backend_verify_call_outs(me);
       PROTECT_CALL_OUTS();
       ret=allocate_array_no_init(me->num_pending_calls,0);
       for(e=0;e<me->num_pending_calls;e++)
       {
	 struct array *v;
	 v=allocate_array_no_init(CALL(e)->args->size+2, 0);
	 ITEM(v)[0].u.integer=CALL(e)->tv.tv_sec - current_time.tv_sec;
	 
	 if(CALL(e)->caller)
	 {
	   ITEM(v)[1].type=T_OBJECT;
	   add_ref(ITEM(v)[1].u.object=CALL(e)->caller);
	   v->type_field = BIT_INT|BIT_OBJECT;
	 }else{
	   v->type_field = BIT_INT;
	 }

	 v->type_field |=
	   assign_svalues_no_free(ITEM(v)+2,
				  ITEM(CALL(e)->args),
				  CALL(e)->args->size,BIT_MIXED);
	 
	 ITEM(ret)[e].type=T_ARRAY;
	 ITEM(ret)[e].u.array=v;
       }
       ret->type_field = BIT_ARRAY;
       UNPROTECT_CALL_OUTS();
       return ret;
     }

/*! @decl array(array) call_out_info()
 *!
 *! Get info about all call_outs.
 *!
 *! This function returns an array with one entry for each entry in the
 *! call out queue. The first in the queue will be at index 0. Each index
 *! contains an array that looks like this:
 *! @array
 *!   @elem int time_left
 *!     Time remaining in seconds until the call_out is to be performed.
 *!   @elem object caller
 *!     The object that scheduled the call_out.
 *!   @elem function fun
 *!     Function to be called.
 *!   @elem mixed ... args
 *!     Arguments to the function.
 *! @endarray
 *!
 *! @seealso
 *!   @[call_out()], @[find_call_out()], @[remove_call_out()]
 */
   PIKEFUN array(array) call_out_info()
     {
       RETURN backend_get_all_call_outs(THIS);
     }

   /*! @decl int id()
    *!
    *! Return an integer that uniquely identifies this backend. For
    *! the default backend that integer is @expr{0@}.
    */
   PIKEFUN int id()
   {
     RETURN (THIS->id);
   }

   PIKEFUN string _sprintf(int type, mapping flags)
   {
     if (type == 'O') {
       push_constant_text ("Pike.Backend(%d)");
       push_int (THIS->id);
       f_sprintf (2);
       stack_pop_n_elems_keep_top (args);
     }
     else {
       pop_n_elems (args);
       push_int (0);
     }
   }

  extern int pike_make_pipe(int *);

#ifdef PIKE_DEBUG
  GC_CHECK
    {
      struct Backend_struct *me =
	(struct Backend_struct *) Pike_fp->current_storage;
      int e;
      PROTECT_CALL_OUTS();
      for (e = 0; e < me->num_pending_calls; e++) {
	if (CALL(e)->caller)
	  gc_mark_external (CALL(e)->caller,
			    " as caller for call out in backend object");
	if (CALL(e)->args)
	  gc_mark_external (CALL(e)->args,
			    " as call out args in backend object");
      }
      UNPROTECT_CALL_OUTS();
    }
#endif

  INIT
    {
      struct Backend_struct *me = THIS;

      me->id = unused_id++;

      IF_PD (fprintf (stderr, "BACKEND[%d]: init\n", me->id));

      me->exec_thread = 0;

      me->backend_callbacks.callbacks=0;
      me->backend_callbacks.num_calls=0;

      GETTIMEOFDAY(&current_time); /* Why? /mast */

      me->num_pending_calls=0;
      me->call_buffer=0;
      me->call_buffer_size=0;
      me->hash_size=0;
      me->hash_order=5;
      me->call_hash=0;

      me->backend_obj = Pike_fp->current_object; /* Note: Not refcounted. */

#ifdef PIKE_DEBUG
      me->inside_call_out=0;
#endif

      me->fds=0;
      me->fds_size=0;

#ifndef HAVE_POLL
      me->set.max_fd=0;
      my_FD_ZERO(&me->set.read);
      my_FD_ZERO(&me->set.write);
      my_FD_ZERO(&me->set.except);
      /* FIXME: Should there be something else here? */
      /* me->set.num_fds=0; */
#else /* HAVE_POLL */
      me->set.poll_fds=0;
      me->set.poll_fd_size=0;
      me->set.num_in_poll=0;

      me->active_set.poll_fds=0;
      me->active_set.poll_fd_size=0;
      me->active_set.num_in_poll=0;
#endif /* !HAVE_POLL */

      if(pike_make_pipe(me->wakeup_pipe) < 0)
	Pike_error("Couldn't create backend wakeup pipe! errno=%d.\n",errno);

      set_nonblocking(me->wakeup_pipe[0],1);
      set_nonblocking(me->wakeup_pipe[1],1);
      set_backend_for_fd (me->wakeup_pipe[0], me);
      backend_set_read_callback(me,
				me->wakeup_pipe[0],
				wakeup_callback,
				0); 
      /* Don't keep these on exec! */
      set_close_on_exec(me->wakeup_pipe[0], 1);
      set_close_on_exec(me->wakeup_pipe[1], 1);
    }
  
  EXIT
    {
      struct Backend_struct *me=THIS;
      int e;

      IF_PD (fprintf (stderr, "BACKEND[%d]: exit\n", me->id));

      /* Make sure we aren't referenced any more. */
      /* FIXME: Ought to keep better track of our fds so that we don't
       * need to do this loop. /mast */
      for (e = 0; e < fd_map_size; e++) {
	if (fd_map[e] == me) fd_map[e] = NULL;
      }

      free_callback_list(& THIS->backend_callbacks);

      fd_close(THIS->wakeup_pipe[0]);
      fd_close(THIS->wakeup_pipe[1]);

      if (me->fds) {
	free(me->fds);
	me->fds = NULL;
	me->fds_size = 0;
      }
#ifdef HAVE_POLL
      if (me->set.poll_fds) {
	free(me->set.poll_fds);
	me->set.poll_fds = NULL;
	me->set.poll_fd_size = 0;
	me->set.num_in_poll = 0;
      }
      if (me->active_set.poll_fds) {
	free(me->active_set.poll_fds);
	me->active_set.poll_fds = NULL;
	me->active_set.poll_fd_size = 0;
	me->active_set.num_in_poll = 0;
      }
#endif /* HAVE_POLL */

      /* CALL OUT */
      backend_verify_call_outs(me);
      for(e=0;e<me->num_pending_calls;e++)
      {
	free_array(CALL(e)->args);
	if(CALL(e)->caller) free_object(CALL(e)->caller);
	really_free_call_out_s(CALL(e));
      }
      if(me->call_buffer) free((char*)me->call_buffer);
      if(me->call_hash) free((char*)me->call_hash);
      me->num_pending_calls=0;
      me->call_buffer=NULL;
    }
}

/*! @endclass
 */

/*! @module DefaultBackend
 *!   This is the @[Backend] object that files and call_outs are
 *!   handled by by default.
 *!
 *!   This is also the @[Backend] object that will be used if @[main()]
 *!   returns @expr{-1@}.
 *!
 *! @seealso
 *!   @[Backend], @[Stdio.File()->set_nonblocking()], @[call_out()]
 */

/*! @endmodule
 */

/*! @endmodule
 */

/*! @decl mixed call_out(function f, float|int delay, mixed ... args)
 *! @decl void _do_call_outs()
 *! @decl int find_call_out(function f)
 *! @decl int find_call_out(mixed id)
 *! @decl int remove_call_out(function f)
 *! @decl int remove_call_out(function id)
 *! @decl array(array) call_out_info()
 *!   These are aliases for the corresponding functions in
 *!   @[Pike.DefaultBackend].
 *!
 *! @seealso
 *!   @[Pike.Backend()->call_out()], @[Pike.Backend()->_do_call_outs()],
 *!   @[Pike.Backend()->find_call_out()], @[Pike.Backend()->remove_call_out()],
 *!   @[Pike.Backend()->call_out_info()]
 */

/* This doesn't need to be here */
PMOD_EXPORT int write_to_stderr(char *a, size_t len)
{
#ifdef __NT__
  size_t e;
  for(e=0;e<len;e++)
    putc(a[e],stderr);
#else
  int nonblock=0;
  size_t pos;
  int tmp;
  
  if(!len) return 1;
  
  for(pos=0;pos<len;pos+=tmp)
  {
    tmp=write(2,a+pos,len-pos);
    if(tmp<0)
    {
      tmp=0;
      switch(errno)
      {
#ifdef EWOULDBLOCK
	case EWOULDBLOCK:
	  nonblock=1;
	  set_nonblocking(2,0);
	  continue;
#endif
	  
	case EINTR:
	  check_threads_etc();
	  continue;
      }
      break;
    }
  }
  
  if(nonblock)
    set_nonblocking(2,1);
  
#endif
  return 1;
}

PMOD_EXPORT struct object *get_backend_obj_for_fd (int fd)
{
  struct Backend_struct *b = really_get_backend_for_fd (fd);
  if (!b) return NULL;
  return b->backend_obj;
}

PMOD_EXPORT void set_backend_for_fd (int fd, struct Backend_struct *new)
{
  struct Backend_struct *old = get_backend_for_fd (fd);

  if (!old)
    low_set_backend_for_fd (fd, new);
  else if (old != new) {
    if (new) {
      file_callback read_cb = backend_query_read_callback (old, fd);
      void *read_cb_data = backend_query_read_callback_data (old, fd);
      file_callback write_cb = backend_query_write_callback (old, fd);
      void *write_cb_data = backend_query_write_callback_data (old, fd);
      file_callback read_oob_cb = backend_query_read_oob_callback (old, fd);
      void *read_oob_cb_data = backend_query_read_oob_callback_data (old, fd);
      file_callback write_oob_cb = backend_query_write_oob_callback (old, fd);
      void *write_oob_cb_data = backend_query_write_oob_callback_data (old, fd);

      low_set_backend_for_fd (fd, new);

      backend_set_read_callback (new, fd, read_cb, read_cb_data);
      backend_set_write_callback (new, fd, write_cb, write_cb_data);
      backend_set_read_oob_callback (new, fd, read_oob_cb, read_oob_cb_data);
      backend_set_write_oob_callback (new, fd, write_oob_cb, write_oob_cb_data);
    } else {
      low_set_backend_for_fd (fd, NULL);
    }
    backend_set_read_callback (old, fd, NULL, NULL);
    backend_set_write_callback (old, fd, NULL, NULL);
    backend_set_read_oob_callback (old, fd, NULL, NULL);
    backend_set_write_oob_callback (old, fd, NULL, NULL);
  }
}

#define WRAP(CB)							\
  void PIKE_CONCAT(set_,CB)(int fd, file_callback cb, void *data)	\
  {									\
    if (cb || data || get_backend_for_fd(fd))				\
      PIKE_CONCAT(backend_set_,CB)(really_get_backend_for_fd(fd),	\
				   fd, cb, data);			\
  }									\
  									\
  file_callback PIKE_CONCAT(query_,CB)(int fd)				\
  {									\
    struct Backend_struct *b=get_backend_for_fd(fd);			\
    if(!b) return 0;							\
    return PIKE_CONCAT(backend_query_,CB)(b, fd);			\
  }									\
  									\
  void * PIKE_CONCAT3(query_,CB,_data)(int fd)				\
  {									\
    struct Backend_struct *b=get_backend_for_fd(fd);			\
    if(!b) return 0;							\
    return PIKE_CONCAT3(backend_query_,CB,_data)(b, fd);		\
  }

WRAP(read_callback);
WRAP(write_callback);
WRAP(read_oob_callback);
WRAP(write_oob_callback);

PMOD_EXPORT struct callback *debug_add_backend_callback(callback_func call,
							void *arg,
							callback_func free_func)
{
  return backend_debug_add_backend_callback(default_backend,
					    call,
					    arg,
					    free_func);
}

void wake_up_backend(void)
{
  if(default_backend)
    backend_wake_up_backend(default_backend);
}

void do_call_outs(void)
{
  if(default_backend) {
    GETTIMEOFDAY (&current_time);
    backend_do_call_outs(default_backend);
  }
}

#ifdef PIKE_DEBUG
long do_debug_cycle=1;
long current_do_debug_cycle=0;
void do_debug(void)
{
  extern void check_all_arrays(void);
  extern void check_all_mappings(void);
  extern void check_all_programs(void);
  extern void check_all_objects(void);
  extern void verify_shared_strings_tables(void);
  extern void slow_check_stack(void);

  if(current_do_debug_cycle) return;
  current_do_debug_cycle=++do_debug_cycle;

  if (d_flag > 2) {
    verify_shared_strings_tables();
    slow_check_stack();
    check_all_arrays();
    check_all_mappings();
    check_all_programs();
    check_all_objects();
  }

  call_callback(& do_debug_callbacks, 0);

  if(default_backend)
    backend_do_debug(default_backend);

  if(d_flag>3) do_gc(NULL, 1);

  current_do_debug_cycle=0;
}
#endif /* PIKE_DEBUG */


void init_backend(void)
{
  init_call_out_s_blocks();
  INIT;
  {
    struct object *o=clone_object(Backend_program,0);
    default_backend=OBJ2_BACKEND(o);
    add_object_constant("__backend",o,0);
    free_object(o);
  }
}


void exit_backend()
{
  EXIT;
  default_backend=0;
  free_all_call_out_s_blocks();
  if(fd_map)
  {
    free(fd_map);
    fd_map=0;
    fd_map_size=0;
  }
#ifdef HAVE_BROKEN_F_SETFD
  cleanup_close_on_exec();
#endif /* HAVE_BROKEN_F_SETFD */
}
